{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大数据分析实验1\n",
    "\n",
    "*环境配置真的烦*\n",
    "\n",
    "我是用的是hadoop streaming+python的方法实现的，这里为了方便map和reduce写在一起了\n",
    "\n",
    "## 数据抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "\n",
    "'''\n",
    "review_id|longitude|latitude|altitude|review_date|temperature|rating|user_id|user_birthday|usr_nationality|user_career|usr_income\n",
    "\n",
    "user_career\n",
    "\n",
    "'''\n",
    "\n",
    "#首先对职业进行计数并计算分层抽样个数 一个Map Reduce\n",
    "f=open('./data.txt','r')\n",
    "careers={}\n",
    "for line in f.readlines():\n",
    "    line=line.replace('\\n','')\n",
    "    career=line.split('|')[-2]\n",
    "    #这里输出 career 1 Map阶段结束\n",
    "    \n",
    "    #reduce\n",
    "    if career in careers.keys():\n",
    "        careers[career]=careers[career]+1\n",
    "    else:\n",
    "        careers[career]=1\n",
    "\n",
    "f.close()\n",
    "f=open('./career_count.txt','w')\n",
    "lines=[]\n",
    "for career in careers.keys():\n",
    "    line=career+' '+str(int(careers[career]*0.02))+'\\n'\n",
    "    lines.append(line)\n",
    "lines[-1]=lines[-1].replace('\\n','')\n",
    "f.writelines(lines)\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行分层抽样\n",
    "career_counts={'programmer':12002,'teacher':12150,'farmer':12009,'doctor':11916,'Manager':11910,'accountant':11747,'artist':11803,'writer':12131}\n",
    "\n",
    "f=open('./data.txt','r')\n",
    "f1=open('./D_Sample.txt','w')\n",
    "lines=[]\n",
    "for line in f.readlines():\n",
    "    line=line.replace('\\n','')\n",
    "    \n",
    "    career=line.split('|')[-2]\n",
    "    if career_counts[career]>0:\n",
    "        new_line=line+'\\n'\n",
    "        lines.append(new_line)\n",
    "        career_counts[career]=career_counts[career]-1\n",
    "\n",
    "f.close()\n",
    "lines[-1]=lines[-1].replace('\\n','')\n",
    "f1.writelines(lines)\n",
    "f1.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "review_id|longitude|latitude|altitude|review_date|temperature|rating|user_id|user_birthday|usr_nationality|user_career|usr_income\n",
    "\n",
    "longitude latitude\n",
    "\n",
    "'''\n",
    "longitude_min=8.1461259 \n",
    "latitude_min=56.5824856\n",
    "longitude_max=11.1993265\n",
    "latitude_max=57.750511\n",
    "\n",
    "\n",
    "f=open('./D_Sample.txt','r')\n",
    "f1=open('./D_Filter.txt','w')\n",
    "lines=[]\n",
    "for line in f.readlines():\n",
    "    line=line.replace('\\n','')\n",
    "    \n",
    "    longitude=float(line.split('|')[1])\n",
    "    latitude=float(line.split('|')[2])\n",
    "    \n",
    "    if longitude>longitude_min and longitude<longitude_max and latitude>latitude_min and latitude<latitude_max:\n",
    "        new_line=line+'\\n'\n",
    "        lines.append(new_line)\n",
    "\n",
    "f.close()\n",
    "lines[-1]=lines[-1].replace('\\n','')\n",
    "f1.writelines(lines)\n",
    "f1.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据标准化和归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "review_id|longitude|latitude|altitude|review_date|temperature|rating|user_id|user_birthday|usr_nationality|user_career|usr_income\n",
    "\n",
    "std:user_birthday review_date temperature\n",
    "\n",
    "1:rating\n",
    "\n",
    "'''\n",
    "# 统计rating最大最小值\n",
    "\n",
    "f=open('./D_Filter.txt','r',encoding='utf-8')\n",
    "rating_max=83\n",
    "rating_min=78\n",
    "count=1\n",
    "max_line=1\n",
    "min_line=1\n",
    "for line in f.readlines():\n",
    "    line=line.replace('\\n','')\n",
    "    \n",
    "    rating=line.split('|')[6]\n",
    "    if rating!='?':\n",
    "        rating=float(rating)\n",
    "        if rating>rating_max:\n",
    "            max_line=count\n",
    "            rating_max=rating\n",
    "        if rating<rating_min:\n",
    "            rating_min=rating\n",
    "            min_line=count\n",
    "    count+=1\n",
    "\n",
    "f.close()\n",
    "f=open('./rating_minmax.txt','w')\n",
    "f.writelines(str(rating_min)+'\\n')\n",
    "f.writelines(str(rating_max))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "review_id|longitude|latitude|altitude|review_date|temperature|rating|user_id|user_birthday|usr_nationality|user_career|usr_income\n",
    "\n",
    "std:user_birthday review_date temperature\n",
    "\n",
    "'''\n",
    "\n",
    "month_dict={'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,'July':7,'August':8,'September':9,'October':10,'November':11,'December':12}\n",
    "\n",
    "f=open('./D_Filter.txt','r',encoding='utf-8')\n",
    "rating_max=101.63\n",
    "rating_min=-261.13\n",
    "\n",
    "\n",
    "def time_std(time_):\n",
    "    if '/' in time_:\n",
    "        return YMD2Y_M_D(time_)\n",
    "    elif ',' in time_:\n",
    "        return MDY2Y_M_D(time_)\n",
    "    else:\n",
    "        return time_\n",
    "    \n",
    "def tem_std(tem):\n",
    "    if '℉' in tem:\n",
    "        return F2C(tem)\n",
    "    else:\n",
    "        return tem\n",
    "\n",
    "def YMD2Y_M_D(ymd):\n",
    "    [year,month,day]=ymd.split('/')\n",
    "    return year+'-'+month+'-'+day\n",
    "\n",
    "def MDY2Y_M_D(mdy):\n",
    "    month=mdy.split(' ')[0]\n",
    "    [day,year]=mdy.split(' ')[1].split(',')\n",
    "    return year+'-'+str(month_dict[month])+'-'+day\n",
    "\n",
    "def F2C(f_tem):\n",
    "    ftem=float(f_tem.replace('℉',''))\n",
    "    ctem=(ftem-32)/1.8\n",
    "    ctem='%.2f'%ctem\n",
    "    return str(ctem)+'℃'\n",
    "\n",
    "def rating_1(rating):\n",
    "    if rating=='?':\n",
    "        return rating\n",
    "    else:\n",
    "        rating=float(rating)\n",
    "        rating=(rating-rating_min)/(rating_max-rating_min)\n",
    "        rating='%.2f'%rating\n",
    "        return rating\n",
    "    \n",
    "lines=[]\n",
    "\n",
    "for line in f.readlines():\n",
    "    line=line.replace('\\n','')\n",
    "    new_line=''\n",
    "    line_split=line.split('|')\n",
    "    rating=line_split[6]\n",
    "    user_birthday=line_split[8]\n",
    "    review_date=line_split[4]\n",
    "    temperature=line_split[5]\n",
    "    \n",
    "    line_split[6]=rating_1(rating)\n",
    "    line_split[8]=time_std(user_birthday)\n",
    "    line_split[4]=time_std(review_date)\n",
    "    line_split[5]=tem_std(temperature)\n",
    "    \n",
    "    for word in line_split:\n",
    "        new_line+=word\n",
    "        new_line+='|'\n",
    "    new_line=new_line[:-1]+'\\n'\n",
    "    lines.append(new_line)\n",
    "f.close()\n",
    "\n",
    "lines[-1]=lines[-1].replace('\\n','')\n",
    "f=open('./D_Filter.txt','w',encoding='utf-8')\n",
    "f.writelines(lines)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "review_id|longitude|latitude|altitude|review_date|temperature|rating|user_id|user_birthday|usr_nationality|user_career|usr_income\n",
    "\n",
    "rating user_income\n",
    "\n",
    "rating:user_income longitude latitude altitude\n",
    "user_income:usr_nationality user_career\n",
    "\n",
    "首先填充user_income选取usr_nationality user_career相同的平均值填充\n",
    "之后选取rating缺失值的user_income longitude latitude altitude与其他最为接近的rating填充\n",
    "\n",
    "'''\n",
    "\n",
    "#首先填充user_income\n",
    "import numpy as np\n",
    "\n",
    "f=open('./D_Filter.txt','r',encoding='utf-8')\n",
    "liens=[]\n",
    "\n",
    "nc_i_dict={}\n",
    "\n",
    "Full_lines=[]\n",
    "Missing_lines=[]\n",
    "count=0\n",
    "all_income=0\n",
    "\n",
    "for line in f.readlines():\n",
    "    line=line.replace('\\n','')\n",
    "    \n",
    "    line_split=line.split('|')\n",
    "    # print(line_split)\n",
    "    user_income=line_split[-1]\n",
    "    usr_nationality=line_split[-3]\n",
    "    user_career=line_split[-2]\n",
    "    if user_income!='?':\n",
    "        count+=1\n",
    "        all_income+=int(user_income)\n",
    "        Full_lines.append(line+'\\n')\n",
    "        dictkey=usr_nationality+user_career\n",
    "        if dictkey in nc_i_dict.keys():\n",
    "            nc_i_dict[dictkey].append(int(user_income))\n",
    "        else:\n",
    "            nc_i_dict[dictkey]=[int(user_income)]\n",
    "    else:\n",
    "        Missing_lines.append(line)\n",
    "income_mean=all_income/count\n",
    "\n",
    "for miss_line in Missing_lines:\n",
    "    line_split= miss_line.split('|')\n",
    "    usr_nationality=line_split[-3]\n",
    "    user_career=line_split[-2]\n",
    "    dictkey=usr_nationality+user_career\n",
    "    if dictkey in nc_i_dict.keys():\n",
    "        line_split[-1]=str(int(np.array(nc_i_dict[dictkey]).mean()))\n",
    "    else:\n",
    "        line_split[-1]=str(int(income_mean))\n",
    "    new_line=''\n",
    "    for word in line_split:\n",
    "        new_line+=word\n",
    "        new_line+='|'\n",
    "    new_line=new_line[:-1]+'\\n'\n",
    "    Full_lines.append(new_line)\n",
    "\n",
    "Full_lines[-1]=Full_lines[-1].replace('\\n','')\n",
    "\n",
    "f.close()\n",
    "f=open('./income_fill.txt','w',encoding='utf-8')\n",
    "f.writelines(Full_lines)\n",
    "f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "review_id|longitude|latitude|altitude|review_date|temperature|rating|user_id|user_birthday|usr_nationality|user_career|usr_income\n",
    "\n",
    "rating user_income\n",
    "\n",
    "rating:user_income longitude latitude altitude\n",
    "user_income:usr_nationality user_career\n",
    "\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def nearest_rating(re,values):\n",
    "    des_n=100000\n",
    "    rating=0\n",
    "    for r in re:\n",
    "        ref_value=r[:-1]\n",
    "        des=np.sqrt(np.sum((np.array(ref_value)-np.array(values))**2))\n",
    "        if des<des_n:\n",
    "            des_n=des\n",
    "            rating=ref_value[-1]\n",
    "    return '%.2f'%rating\n",
    "\n",
    "\n",
    "f=open('./income_fill.txt','r',encoding='utf-8')\n",
    "liens=[]\n",
    "\n",
    "Full_lines=[]\n",
    "Missing_lines=[]\n",
    "\n",
    "re=[]\n",
    "#user_income longitude latitude altitude rating\n",
    "\n",
    "for line in f.readlines():\n",
    "    line=line.replace('\\n','')\n",
    "    \n",
    "    \n",
    "    line_split=line.split('|')\n",
    "    rating=line_split[6]\n",
    "    user_income=line_split[-1]\n",
    "    longitude=line_split[1]\n",
    "    latitude=line_split[2]\n",
    "    altitude=line_split[3]\n",
    "    \n",
    "    if rating != '?':\n",
    "        Full_lines.append(line+'\\n')\n",
    "        re.append([int(user_income),float(longitude),float(latitude),float(altitude),float(rating)])\n",
    "    else:\n",
    "        Missing_lines.append(line)\n",
    "\n",
    "f.close()\n",
    "for line in Missing_lines:\n",
    "    line_split=line.split('|')\n",
    "    # rating=line_split[6]\n",
    "    user_income=line_split[-1]\n",
    "    longitude=line_split[1]\n",
    "    latitude=line_split[2]\n",
    "    altitude=line_split[3]\n",
    "    line_split[6]=nearest_rating(re,[int(user_income),float(longitude),float(latitude),float(altitude)])\n",
    "    new_line=''\n",
    "    for word in line_split:\n",
    "        new_line+=word\n",
    "        new_line+='|'\n",
    "    new_line=new_line[:-1]+'\\n'\n",
    "    Full_lines.append(new_line)\n",
    "\n",
    "Full_lines[-1]=Full_lines[-1].replace('\\n','')\n",
    "\n",
    "f=open('./D_done.txt','w',encoding='utf-8')\n",
    "f.writelines(Full_lines)\n",
    "f.close()\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
