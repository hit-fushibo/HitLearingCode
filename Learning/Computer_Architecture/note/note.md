# 哈工大计算机体系结构笔记

## 第一章-计算机体系结构的基本概念

### 1.1 计算机体系结构的概念

#### 1.1.1 存储程序计算机

![1700385634050](images/1700385634050.png)

四个组成部分：

- 运算器
- 存储器
- 输入输出设备
- 控制器

主要特点：

1. 以运算器为中心
2. 采用存储程序原理
3. 存储器是按地址访问的
4. 控制流由指令流产生
5. 指令由操作码和地址码组成
6. 数据以二进制编码表示

![1700385786309](images/1700385786309.png)

#### 1.1.2 计算机体系结构、组成和实现

计算机体系结构的概念由**阿姆道尔**于 1964 年首次明确：程序员所看到的计算机的属性，即概念性结构与功能特性。

对于通用寄存器型的机器，这些属性主要是指：

1. 数据表示
2. 寻址规则
3. 寄存器定义
4. 指令系统
5. 中断系统
6. 机器工作状态的定义和切换
7. 存储系统
8. 信息保护
9. I/O 结构

计算机体系结构包括以下三个方面：

1. 计算机指令系统 ISA
2. 计算机组成
3. 计算机硬件实现

#### 1.1.3 系列机和兼容

**系列机**：具有相同体系结构，但组成和实现不同的一系列不同型号的计算机系统

一种体系结构可以有多种组织、多种物理实现。

**软件兼容**：

- 系列机具有相同的体系结构，软件可以在系列计算机的各档机器上运行。
- 同一个软件可以不加修改地运行于体系结构相同的各档机器，而且它们所获得的结果一样，差别只在于有不同的运行时间。
- 兼容分为二进制级兼容、汇编级兼容、高级语言兼容、数据级兼容等等。

**兼容机**：不同厂家生产的具有相同体系结构的计算机

**兼容性**：

- 向上(下)兼容指的是按某档机器编制的程序，不加修改的就能运行于比它高(低)档的机器
- 向前(后)兼容指的是按某个时期投入市场的某种型号机器编制的程序，不加修改地就能运行于在它之前(后)投入市场的机器

![1700386991606](images/1700386991606.png)

**向下兼容和向后兼容**比向上兼容和向前兼容更重要

### 1.2 计算机体系结构的发展

#### 1.2.1 计算机的分代

一般认为到目前为止计算机已经发展了五代

![1700387141743](images/1700387141743.png)

计算机曾根据价格分为 5 个档次：巨型机、大型机、中型机、小型机、微型机。

![1700387281363](images/1700387281363.png)

技术和性能的“下移”。

新型体系结构的设计一方面是合理地增加计算机系统中硬件的功能比例、另一方面则是通过多种途径提高计算机体系结构中的并行性。

#### 1.2.2 软件的发展

最重要的发展趋势之一：程序和数据使用的存储器容量不断扩大。

1. 计算机语言和编译技术
2. 操作系统
3. 软件工具和中间件

#### 1.2.3 应用的发展

计算机技术和市场分为嵌入式计算机、掌上计算机、台式计算机、服务器、数据中心。

#### 1.2.4 相关核心产品技术的发展

1. 逻辑电路 摩尔定律
2. DRAM 单个 DRAM 模块的容量每年增加 25-40%，增速逐年下降。
3. 闪存 近几年，每年约 50-60%的速度增长，大约每两年翻一番，大量用于便携式设备。
4. 磁盘 从 04 年开始，大约每年增长 40%，约每 3 年翻一番。SSD 的成本的迅速下降。
5. 网络

#### 1.2.5 体系结构的发展

1. 分布的 I/O 处理能力
2. 保护的存储器空间
3. 存储器组织结构的发展
4. 并行处理技术
5. 指令集的发展

#### 1.2.6 并行处理技术的发展

并行性：计算机系统在同一时刻或者同一时间间隔内进行多种运算或操作。只要时间上相互重叠，就存在并行性。

- 同时性：两个及以上的事件在同一时刻发生
- 并发性：两个及以上的事件在同一时间间隔内发生

从执行程序的角度来看，并行性等级从低到高可分为：

- 指令内部并行： 单条指令中各微操作之间的并行。
- 指令级并行：并行执行两条或两条以上的指令。
- 线程级并行：并行执行两个或两个以上的线程。通常是以一个进程内派生的多个线程为调度单位。
- 任务级或过程级并行：并行执行两个或两个以上的过程或任务（程序段）， 以子程序或进程为调度单元。
- 作业或程序级并行：并行执行两个或两个以上的作业或程序。

从处理数据的角度来看， 并行性等级从低到高可分为：

- 字串位串：每次只对一个字的一位进行处理。最基本的串行处理方式，不存在并行性。
- 字串位并：同时对一个字的全部位进行处理，不同字之间是串行的。开始出现并行性。
- 字并位串：同时对许多字的同一位（称为位片）进行处理。具有较高的并行性。
- 全并行：同时对许多字的全部位或部分位进行处理。最高一级的并行。

计算机系统结构的 Flynn 分类法：按照指令和数据的关系，把计算机系统的结构分为 4 类：

- 单指令流单数据流 SISD（Single Instruction stream Single Data stream）
- 单指令流多数据流 SIMD（Single Instruction stream Multiple Data stream）
- 多指令流单数据流 MISD（Multiple Instruction stream Single Data stream）
- 多指令流多数据流 MIMD（Multiple Instruction stream Multiple Data stream）

提高并行性的途径;

1. 时间重叠
2. 资源重复
3. 资源共享

在单机系统并行性的发展中：

- 起主导作用的是时间重叠，基础是部件功能专用化
- 资源重复运用也十分普遍

![1700388531801](images/1700388531801.png)

- 资源共享的实质上是用单处理机模拟多处理机的功能

在多级系统并行性的发展中，遵循时间重叠、资源重复、资源共享原理，发展为 3 种不同的多处理机：同构型多处理机、异构型多处理机、分布式系统。

耦合度：反映多机系统中各机器之间物理连接的紧密程度和交互作用能力的强弱。

![1700388674438](images/1700388674438.png)

### 1.3 计算机系统设计和分析

#### 1.3.1 成本和价格

商品的标价由这样一些因素构成：原料成本、直接成本、毛利和折扣。

性能/成本设计：设计者需取得性能与成本之间的平衡。

对计算机系统成本产生影响的主要因素有：时间、产量、商品化等。最直接的影响是时间。

#### 1.3.2 基准测试程序

五类测试程序：

1. 真实程序
2. 修正的（或者脚本化）应用程序
3. 核心测试程序
4. 小测试程序
5. 合成测试程序

测试程序包

#### 1.3.1 量化设计基本原则

大概率事件优先原则：对于大概率事件(最常见的事件)，赋予它优先的处理权和资源使用权，以获得全局的最优结果

Amdahl 定律：

$$
\text{系统加速比}=\frac{\text{总执行时间}_\text{加速前}}{\text{总执行时间}_\text{加速后}}=\frac{1}{(1-\text{可改进比例})+\frac{\text{可改进比例}}{部件加速比}}
$$

![1700389397512](images/1700389397512.png)

程序的局部性原理：程序总是趋向于使用最近使用过的数据和指令。

CPU 的性能公式：

$$
T_{CPU}=CPI\times IC\times T_{CLK}
$$

进一步细化：一共有$n$条指令，第$i$条指令处理时间为$CPI_i$，出现次数为$IC_i$

$$
T_{CPU}=\sum_i{IC_i\times CPI_i\times T_{CLK}}\\CPI=\sum_i{\frac{IC_i}{IC}\times CPI_i}
$$

## 第二章 指令系统

### 2.1 指令系统概述

指令系统是计算机系统中软件与硬件交界的一个主要标志：

- 软件设计人员利用指令系统编制各种应用软件和系统软件
- 硬件设计人员采用各种手段实现指令系统

### 2.2 指令集结构的分类

一般来说，可以从如下五个因素考虑对计算机指令集结构进行分类，即：

- **在 CPU 中操作数的存储方法**
  - 堆栈
  - 累加器
  - 寄存器
- 指令中显式表示的操作数个数
- 操作数的寻址方式
- 指令集所提供的操作类型
- 操作数的类型和大小

指令中的操作数可以被明确地显式给出，也可以按照某种约定隐式地给出。

Z=X+Y 在这三种指令集结构上的实现方法

![1700466505043](images/1700466505043.png)

通用寄存器型指令集结构的优点：

- 在表达式求值方面，比其它类型指令集结构都具有更大的灵活性
- 寄存器可以用来存放变量
  - 寄存器比存储器快，减少了存储器的通信量，加快程序执行速度
  - 可以用更少的地址位来寻址寄存器，有效改进程序代码大小。

通用寄存器型指令集结构可以进一步细分：

- 寄存器-寄存器型 R-R
- 寄存器-存储器型 R-M
- 存储器-存储器型 M-M

![1700466730205](images/1700466730205.png)

三类指令集的优缺点：

![1700466815358](images/1700466815358.png)

### 2.3 寻址方式

![1700466885441](images/1700466885441.png)

两种表示寻址方式的方法：

- 将寻址方式编码与操作码中，由操作码描述相应操作的寻址方式。
  - 适合：采用 load-store 结构的处理机，寻址方式只有很少几种。MIPS 指令集
- 在指令字中设置专门的寻址字段，直接指出寻址方式。
  - 灵活，操作码短，但需要设置专门的寻址方式字段，而且操作码和寻址方式字段合起来所需要的总位数可能会比隐含方法的总位数多。
  - 适合：有多种寻址方式的处理机，且指令有多个操作数。VAX11

数据在内存中存放要对齐：信息在主存中存放的起始地址必须是该信息宽度（字节数）的整数倍。

![1700467157145](images/1700467157145.png)

**存在空间浪费，但保证访问速度。**

### 2.4 操作数类型和大小

![1700467309303](images/1700467309303.png)

![1700467322204](images/1700467322204.png)

![1700467335270](images/1700467335270.png)

![1700467344542](images/1700467344542.png)

![1700467358347](images/1700467358347.png)

操作数大小主要有：字节、半字 16、单字 32、双字 64。

### 2.5 指令系统的设计和优化

#### 2.5.1 指令系统设计的基本原则

指令系统的设计：

- 指令的功能设计
- 指令的格式设计

确定哪些功能由硬件实现，主要考虑三个因素：速度，成本，灵活性。

- 硬件实现：快、高、差
- 软件实现：慢、低、好

对指令系统的基本要求：

- 完整性：在一个有限可用的存储空间内，对于任何可解的问题，编制计算程序时，指令系统所提供的指令足够使用。
- 规整性：主要包括对称性和均匀性。

  - 对称性：所有与指令系统有关的存储单元的使用、操作码的设置等都是对称的。
  - 均匀性：指对于各种不同的操作数类型、字长、操作种类和数据存储单元，指令的设置都要同等对待。
- 正交性：在指令中各个不同含义的字段，如操作类型、数据类型、寻址方式字段等，在编码时应互不相关、相互独立。
- 高效率：指令的执行速度快、使用频度高。
- 兼容性：主要是要实现向后兼容，指令系统可以增加新指令，但不能删除指令或更改指令的功能。

#### 2.5.2 控制指令

控制指令是用来改变控制流的，有四种：

- 分支：有条件跳转（大部分）
- 跳转：无条件跳转
- 过程调用
- 过程返回

条件分支指令的表示：

![1700467892008](images/1700467892008.png)

过程调用和返回的状态保存策略：

- 调用者保存
- 被调用者保存

![1700467962107](images/1700467962107.png)

#### 2.5.3 指令操作码的优化

如何用最短的位数表示指令的操作信息和地址信息

等长拓展码：

![1700468120279](images/1700468120279.png)

定长拓展码：操作码长度固定。

### 2.6 指令系统的发展和改进

#### 2.6.1 沿 CISC 方向改进

CISC（复杂指令计算机）

- 面向目标程序增强指令功能：对于使用频度高的指令，用硬件加快其执行；对于使用频度高的指令串，用一条新的指令来替代。
  - 增强运算型指令的功能
  - 增强数据传送指令的功能
  - 增强程序控制指令的功能
- 面向高级语言的优化改进指令系统
  - 增强对高级语言和编译器的支持
  - 高级语言计算机：间接或直接执行高级语言的机器
- 面向操作系统的优化改进指令系统
  - 处理机工作状态和访问方式的切换
  - 进程的管理和切换
  - 存储管理和信息保护
  - 进程的同步与互斥，信号灯的管理

#### 2.6.2 沿 RISC 方向改进

RISC（精简指令计算机）

CISC 的缺点：

- 各指令的使用频率相差悬殊
- 指令系统的复杂性使得控制器硬件变得十分复杂
  - 占用大量芯片面积
  - 增加研发成本和时间，容易造成设计错误
- 其 CPI 值比较大，执行速度慢
- 规整性不好，不利于使用流水线技术提高性能

RISC 指令集设计原则：

![1700468863713](images/1700468863713.png)

### 2.7 MIPS 指令系统结构

寄存器：

- 32 个 32 位通用寄存器，R0 恒为 0
- 32 个 32 位单精度浮点寄存器

数据类型

- 整型数据：8、16、32 位
- 浮点数据：32 位单精度、64 位双精度，IEEE754 标准

寻址方式：

- 寄存器寻址
- 立即寻址
- 偏移寻址
  - 寄存器间接寻址
  - 直接寻址

指令格式：

- I 类指令
  ![1700469220980](images/1700469220980.png)
- R 类指令

  ![1700469266984](images/1700469266984.png)
- J 类指令

  ![1700469276789](images/1700469276789.png)

操作类型：

- Load 和 store 操作
- ALU 操作
- 分支和跳转指令
- 浮点操作

## 第三章 流水线技术

### 3.1 流水线概述

#### 3.1.1 流水线基本概念

流水线技术：将一重复的时序过程分解为若干子过程，每个子过程都可有效地在其专用功能段上与其它子过程同时执行，这种技术称为流水技术。

时空图：从时间和空间两个方面描述流水线的工作过程，横坐标表示时间，纵坐标表示各流水段。

流水线特点：

- 流水过程由多个相关的子过程组成，这些子过程称为流水线的“ 级”或“ 段”。段的数目称为流水线的“ 深度”
- 每个子过程由专用的功能段实现
- 各功能段的时间应基本相等，通常为 1 个时钟周期（ 1 拍）
- 流水线需要经过一定的通过时间才能稳定
- 流水技术适合于大量重复的时序过程

#### 3.1.2 流水线分类

按功能分类：

- 单功能流水线
- 多功能流水线

按同一时间各段之间的连接方式分类：

- 静态流水线
- 动态流水线

按流水的级别分类：

- 部件级流水线
- 处理机级流水线
- 处理机间流水线

按数据表示分类：

- 标量流水处理机
- 向量流水处理机

按是否有反馈回路分类：

- 线性流水线
- 非线性流水线，存在流水线调度问题

### 3.2 MIPS 基本流水线

#### 3.2.1 基本 MIPS 流水线

分为五个周期：取值、译码、执行/有效地址计算、访存/分支、写回

![1700535992678](images/1700535992678.png)

#### 3.2.2 流水线性能分析

三项性能指标：吞吐率、加速比、效率

吞吐率：单位时间内流水线所完成的任务数或输出结果的数量（计算公式：完成的指令条数/完成这些指令条数所需的时间）

- 最大吞吐率：

  - 如果各段时间相等，均为$\Delta t_0$，则$TP_{MAX}=\frac{1}{\Delta t_o}$
    - 如果各段时间不等，第$i$段时间为$\Delta t_i$，则$TP_{MAX}=\frac{1}{\max{\Delta t_i}}$
  - 最大吞吐率取决于流水线中最慢的一段所需时间，该段成为流水线性能瓶颈。消除瓶颈的方法：
    - 细分瓶颈段
    - 重复设置瓶颈段
- 实际吞吐率：m 段流水，n 条指令

  - 如果各段时间相等，均为$\Delta t_0$，那么完成时间$T=m\Delta t_0+(n-1)\Delta t_0$，则实际吞吐率$TP=\frac{n}{T}=\frac{TP_{MAX}}{1+\frac{m-1}{n}}$
  - 如果各段时间不等，第$i$段时间为$\Delta t_i$，那么完成时间$T=\sum_1^m{\Delta t_i}+(n-1)\max{\Delta t_i}$，即第一条指令流出时间+后续指令流出时间。实际吞吐率$TP=\frac{n}{\sum_1^m{\Delta t_i}+(n-1)\max{\Delta t_i}}$

加速比：加速比是指流水线速度与等功能的非流水线速度之比。$S=\frac{T_{\text{非流水}}}{T_{\text{流水}}}$

效率：效率指流水线的设备利用率。

- 由于流水线有通过时间和排空时间，所以效率 E<1
- 效率$E=\frac{S}{m}$
- 也可以通过时空图占用面积与总面积之比得出

有关流水线性能的若干问题：

- 流水线并不能减少（而且一般是增加）单条指令的执行时间，但能够提高吞吐率
- 增加流水线的深度可以提高流水线性能
- 流水线深度受限于流水线的延迟和额外开销
- 需要用高速锁存器作为流水线寄存器- Earle 锁存器
- 指令之间存在的相关，产生了流水线的冲突，进而限制了流水线的性能

### 3.3 流水线中的冲突

流水线冲突：相邻或相近的两条指令因存在某种关联，后一条指令不能在原先指定的时钟周期开始执行。

消除冲突基本方法：暂停

#### 3.3.1 结构冲突

原因：

- 功能部件不是全流水
- 重复设置资源不足

避免方法：

- 所有功能部件全部流水化
- 设置足够多硬件资源，代价很大

#### 3.3.2 数据冲突

原因：当指令在流水线中重叠执行时，流水线有可能改变指令读/写操作数的顺序，使之不同于它们在非流水实现时的顺序，这将导致数据冲突。

消除方法：插入暂停周期，通过定向技术减少暂停

数据冲突分类：

- 写后读冲突(RAW)：最常见
- 写后写冲突(WAW)：MIPS 不会出现
- 读后写冲突(WAR)：MIPS 不会出现
- 读后读冲突(RAR)：不引起冲突

需要暂停的数据冲突：load 指令后紧跟一条使用寄存器的指令时，需要暂停一个周期才能使用定向解决冲突

通过编译器调度消除冲突：

![1700538816651](images/1700538816651.png)

#### 3.3.3 控制冲突

分支指令转移成功在访存段才能得到正确的跳转地址，简单暂停后续指令的指令会导致流水线暂停 3 个周期

减少分支开销的途径：

- 尽早判断是否分支成功
- 分支成功时尽早计算得出转移目标地址

优化时两种方法都要采用

对于 MIPS 流水线的改进：

- 分支测试提前到 ID 段
- 分支地址计算也提前到 ID 段
- 开销降低到 1 拍

减少流水线分支损失的方法：

- 冻结或排空流水线：简单的暂停后续指令的执行
- 预测分支失败：流水线照常流动，如果分支成功则要清空流水线，重新取值执行
- 预测分支成功：始终预测分支成功，直接从目标处取值执行
- 延迟分支：分支开销为 n 的分支指令后紧跟有 n 个延迟槽，遇到分支指令时正常处理并执行延迟槽中指令，减少分支开销。
  - 从前调度
  - 从目标处调度
  - 从失败处调度

![1700540343088](images/1700540343088.png)

取消分支：分支指令中包含预测方向，若预测正确，正常执行延迟槽中的指令，否则将其转换为空操作

分支处理方法的性能：

- 假设理想$CPI=1$，则加速比$S=\frac{D}{1+C}=\frac{D}{1+f\times p_{\text{分支}}}$，$D$为流水线深度，$p_{\text{分支}}$为分支开销，$C$为分支引起的流水线暂停时钟周期数（平均值），$f$为分支指令出现的频率

  ![1700540577567](images/1700540577567.png)

### 3.4 MIPS 流水线分析（略）

### 3.5 向量处理机

处理 d=a\*(b+c)，a、b、c、d 均为水平向量

- 水平处理方式，一位一位计算
- 垂直处理方式，k=b+c,d=a\*k
- 分组处理方式，将长度为 N 的向量分为 m 组，每组 n 个元素，组内纵向处理，依次处理各组

向量机速度评价方法：

- 标量机通常用每秒执行多少指令衡量
- 每秒取得多少浮点运算结果衡量向量机速度

CRAY-1 实例分析（略）

向量流水线：向量链接技术

链接只有在第一个结果流出之后才可以建立。

## 第四章 指令级并行

### 4.1 指令级并行的概念

指令级并行：当指令之间不存在相关时，它们在流水线中是可以重叠起来并行执行的。这种指令序列中存在的**潜在**并行性称为指令级并行，ILP

![1700551698056](images/1700551698056.png)

- 基本程序块：一段除了入口和出口以外不包含其他分支的线性代码段
- 循环级并行：开发循环体的不同迭代之间存在的并行性
  - 指令调度
  - 循环展开
  - 换名

#### 4.1.1 循环展开调度的基本方法

循环展开：展开循环体若干次，将循环级并行转化为指令级并行的技术

编译器在完成这种指令调度时，受限于以下两个特性：

- 程序固有的指令级并行性
- 流水线功能部件的执行延迟

![1700551981380](images/1700551981380.png)

![1700552010545](images/1700552010545.png)

分析以下代码

```C
for(i=1;i<1000;i++){
  x[i]=x[i]+s;
}
```

转变成汇编语言：

![1700552130123](images/1700552130123.png)

无调度：

![1700552180408](images/1700552180408.png)

进行调度之后：

![1700552249386](images/1700552249386.png)

循环展开三次得到四个循环体（无调度）：

![1700552332539](images/1700552332539.png)

循环展开+调度：

![1700552353811](images/1700552353811.png)

这里需要注意，BNEZ 分支指令具有一个分支延迟槽

循环展开和指令调度总结：

- 保证正确性
- 注意有效性
- 使用大量不同寄存器
- 减少循环控制中的测试指令和分支指令
- 注意 LOAD/STORE 的内存地址
- 注意新的相关性

#### 4.1.2 相关性

相关：两条指令之间存在某种依赖关系，如果两条指令相关则它们有可能不能再流水线中重叠执行或只能部分重叠执行

相关的类型：

- 数据相关（真数据相关、数据流相关）
- 名相关（反相关、输出相关）
- 控制相关

数据相关：

- 对于两条指令 i（在前）和 j（在后）如果下述条件之一成立，则称指令 j 与指令 i 数据相关

  - 指令 j 使用指令 i 产生的结果
  - 指令 j 与指令 k 数据相关，而指令 k 与指令 i 数据相关（数据相关具有传递性）
- 数据相关并不一定代表冲突，也不一定就会在流水线中引起暂停
- 数据相关的解决办法：

  - 硬件：采用互锁机制，检测到相关就插入暂停周期
  - 软件：使用编译器在相关处插入空操作
- 对于寄存器的相关判断比较简单，但是存储器就相对复杂

名相关：如果两条指令使用相同的名，但是它们之间并没有数据流动，则称这两条指令存在名相关。

- 分类：
  - 反相关：指令 j 写的名和指令 i 读的名相同（读后写相关）
  - 输出相关：指令 j 和指令 i 写相同的名（写后写相关）
- 解决办法：换名
  - 编译器静态完成或硬件动态完成

控制相关：由分支指令引起的相关

- 两个原则：
  - 与控制相关的指令不能移到分支指令之前，即控制有关的指令不能调度到分支指令的控制范围之外。
  - 与控制无关的指令不能移到分支指令之后，即控制无关的指令不能调度到分支指令的控制范围以内。

### 4.2 指令的动态调度

动态调度

- 目的
  - 在程序执行的时候， 解决 WAW、 WAR、 RAW 带来的流水线冲突
- 优点
  - 处理在编译的时候未知的相关， 简化编译器
  - 在不同的流水线上都能有效的运行
- 缺点：
  - 很大增加了硬件复杂性

#### 4.2.1 动态调度的原理

到目前为止流水线最大的局限性：指令按序流出和按序执行

乱序执行：

- 指令的执行顺序和程序顺序是不同的
- 指令的完成也是乱序完成的
- 为了支持乱序执行将 5 段流水线的译码阶段再分为两个阶段
  - 流出 IS：指令译码，检查是否存在结构冲突
  - 读操作数 RO：等待数据冲突消失，然后读操作数

#### 4.2.2 记分牌算法

两个浮点乘（10 拍延迟）、一个浮点除（40 拍延迟）、一个浮点加（2 拍延迟）、一个整数运算部件

执行过程：

- 流出
  - 是否存在空闲部件（结构冲突）
  - 正在执行的指令使用的目的寄存器和本指令不同（WAW 冲突）
  - 如果不能满足，阻塞本条指令以及后续指令的流出，直到条件都能满足
- 读操作数
  - 前面正在执行的指令不对本指令的源操作数寄存器进行写操作
  - 一个正在工作的功能部件已经完成了对这个寄存器的写操作（RAW 相关）
- 执行
  - 开始于取到操作数之后
  - 结果产生后修改记分牌
- 写结果：检查 WAR 相关，当出现以下情况时，不允许写结果
  - 前面的指令还没有取得操作数而且其源寄存器与本指令目的寄存器相同

记分牌结构：

- 指令状态表：记录指令执行到那个阶段
- 功能部件状态表：
  - Busy：指示功能部件是否工作
  - Op：功能部件当前执行的操作
  - Fi：目的寄存器编号
  - Fj， Fk：源寄存器编号
  - Qj， Qk：向源寄存器 Fj， Fk 中写结果的功能部件
  - Rj， Rk：标示 Fj， Fk 是否就绪，是否已经被使用
- 结果寄存器状态表：记录写入寄存器的功能部件编号

实例：

- 指令序列

  ![1700554678966](images/1700554678966.png)
- 相关性

  - 先写后读相关：第二个 LD 和 MULID、SUBD，MULTD 和 DIVD，SUBD 和 ADDD
  - 先读后写相关：SUBD、DIVD 和 ADDD
  - 写后写相关：第一条 LD 和 ADDD 之间
  - 结构冲突：SUBD 和 ADDD 浮点加部件
- 第一拍：第一条 LD 指令流出，占用整数部件计算目的地址

  ![1700555232190](images/1700555232190.png)
- 第二拍：第二个 LD 无法流出，因为它也需要整数部件，第一个 LD 完成 RO 段

  ![1700555280607](images/1700555280607.png)
- 第三拍，第二条指令依旧阻塞，这里将 Rk 该为 No 并不是说未准备，而是说已经使用完了，同时记分牌依然是**顺序流出**的所以 MULTD 并不流出。

  ![1700555367452](images/1700555367452.png)
- 第四拍，第一条指令写回结果，修改记分牌，结束对整数部件的占用，注意：这时第二条指令仍然不能流出，因为对整数部件的占用在这一拍的后半段才被删除

  ![1700555559112](images/1700555559112.png)
- 5，第二条指令因为结构冲突消除所以可以流出，修改记分牌

  ![1700555599720](images/1700555599720.png)
- 6，第二条指令完成 RO 段，第三条指令不存在结构冲突和 WAW 冲突所以可以流出

  ![1700555668839](images/1700555668839.png)
- 7，因为第二条指令对 MULTD 的源操作数进行写操作，所以 MULTD 指令无法进入 RO 段，而第二条指令完成 EX 段，SUBD 不存在结构冲突和 WAW 相关所以可以流出

  ![1700555814383](images/1700555814383.png)
- 8 前半拍，LD 完成写回操作，修改记分牌，DIVD 不存在结构冲突和 WAW 冲突，流出

  ![1700555964912](images/1700555964912.png)
- 8 后半拍，因为 LD 指令已经写回，所以 MULTD 和 SUBD 的源寄存器可以使用，修改记分牌

  ![1700556135733](images/1700556135733.png)
- 9，ADDD 存在结构相关所以不能流出，DIVD 存在 RAW 冲突所以不能进入 RO 段，MULTD 和 SUBD 完成 RO 段

  ![1700556445514](images/1700556445514.png)
- 10，MUTLD 和 SUBD 开始执行，因为这两个操作都不能在一拍内完成，所以这一拍只是在执行这两条指令

  ![1700556518452](images/1700556518452.png)
- 11，SUBD 指令执行完毕

  ![1700556590297](images/1700556590297.png)
- 12，SUBD 指令写回，ADDD 指令不能流出的原因和第 4 拍相同

  ![1700556617192](images/1700556617192.png)
- 13，ADDD 流出

  ![1700556699686](images/1700556699686.png)
- 14，ADDD 完成 RO 段，开始执行

  ![1700556804915](images/1700556804915.png)
- 15，ADDD 指令执行
- 16，ADDD 指令执行完成

  ![1700556850054](images/1700556850054.png)
- 17，ADDD 无法写回，因为前面 DIVD 使用了 F6 并且还没有取出
- 18，等待 MULTD 执行完成
- 19，MULTD 执行完成

  ![1700556995692](images/1700556995692.png)
- 20，MULTD 写回，修改记分牌

  ![1700557020570](images/1700557020570.png)
- 21，DIVD 的 RAW 冲突解除，完成 RO 段

  ![1700557202571](images/1700557202571.png)
- 22，ADDD 的 WAR 相关解除，写回

  ![1700557264005](images/1700557264005.png)
- 直到 61 拍，DIVD 操作完成

  ![1700557306211](images/1700557306211.png)
- 62，DIVD 写回完成程序运行

  ![1700557328628](images/1700557328628.png)

记分牌流水线控制：

![1700557387582](images/1700557387582.png)

性能受限于以下几个方面：

- 程序代码中可开发的并行性，即是否存在可以并行执行的不相关的指令
- 记分牌的容量
  - 记分牌的容量决定了流水线能在多大范围内寻找不相关指令。流水线中可以同时容纳的指令数量称为指令窗口
- 功能部件的数目和种类
  - 功能部件的总数决定了结构冲突的严重程度
- 反相关和输出相关
  - 它们引起计分牌中更多的 WAR 和 WAW 冲突

#### 4.2.3 Tomasulo 算法

与记分牌的异同：

- 采用许多记分牌中的理念
- 在 Tomasulo 算法中，冲突检测和执行控制是分布的，利用该保留站实现
- Tomasulo 算法不检查 WAR 和 WAW 相关，通过算法本身消除。计算结果通过专用通道直接从功能部件进入到保留站进行缓冲，而不是直接写回到寄存器

核心思想：

- 记录并检测指令的 RAW 相关，操作数一旦准备就绪就立即执行
- 不检查 WAR 和 WAW 相关，通过换名技术消除（保留站实现）

基本结构：

![1700563294142](images/1700563294142.png)

算法流程：

- 算法流水段
  - 流出（Issue）
    - 如果存在一个空闲的保留站，则发射指令和操作数，消除 WAR 和 WAW 相关
  - 执行（Execute）
    - 如果两个操作数准备好就可以指令
    - 如果没有准备好，检测 CDB 以获取结果，通过推迟指令执行避免 RAW 相关
  - 结果写回（Write result）
    - 结果通过 CDB 传给所有等待该结果的部件
- 保留站结构
  - op：对源操作数的操作
  - Qj，Qk：产生源操作数的保留站号
    - 没有记分牌中的准备就绪标志，为零表示就绪
    - Store 缓存区只有 Qk 表示产生结果的保留站号
  - Vj，Vk：两个源操作数的值。Store 缓冲区只有 Vk 域，用于存放要写入存储器的值。V 域和 Q 域不同时有效。
  - Busy：表示本保留站和相应功能部件是否空闲
- 每个寄存器和存缓冲有一个 Qi 域：结果要写入本寄存器或存缓冲的保留站号
- 存缓冲和取缓冲还各有一个 Busy 和 Address 域
  - busy：表示缓冲是否空闲
  - A：地址域，记录存或取的存储器地址
  - 存缓冲还有一个 V 域：写入存储器的值

实例：

- 代码：

  ![1700564667138](images/1700564667138.png)
- 操作延迟：

  ![1700564683675](images/1700564683675.png)
- 运行：

  - 1，第一个 LD 流出，功能部件保留站无变化，取缓冲记录，寄存器记录，（这里隐含一个加法操作延迟）

    ![1700564831452](images/1700564831452.png)
  - 2，第一个 LD 地址计算仍未结束，第二个 LD 由于取缓冲保留站还有空闲，可以流出，这里寄存器加入记录，取缓冲保留站加入记录

    ![1700564982677](images/1700564982677.png)
  - 3，第一个 LD 的地址计算结束，第二个 LD 的地址计算仍在进行，MULTD 由于乘法保留站有空闲所以可以流出，其所需操作数 F4 可以直接取，而 F2 正在被占用

    ![1700565170097](images/1700565170097.png)
  - 4，第一个 LD 写回数据，通过 CDB 送到 F6 和刚流出的 SUBD 中，第二个 LD 地址计算完毕，SUBD 所需操作数一个从 CDB 中送入，一个等待 LD2 的送出

    ![1700657178220](images/1700657178220.png)
  - 5，第二个 LD 写回数据，通过 CDB 送入 F2，MULTD1，ADD1 中，DIVD 由于乘法保留站有空闲所以流出操作数未就绪记录占用信息，并且 MULTD 和 ADD 所需数据都准备完毕，**立即执行，这一点和记分牌不同**

    ![1700657350794](images/1700657350794.png)
  - 6，加法保留站有空闲所以 ADDD 可以流出

    ![1700657455970](images/1700657455970.png)
  - 7，SUBD 执行完成

    ![1700657683728](images/1700657683728.png)
  - 8，SUBD 写回通过 CDB 送入寄存器和 ADDD 指令，ADDD 指令由于操作数都准备好了所以开始执行

    ![1700657753936](images/1700657753936.png)
  - 9，进行操作

    ![1700657788001](images/1700657788001.png)
  - 10，ADDD 操作执行完毕

    ![1700657874397](images/1700657874397.png)
  - 11，ADDD 指令写回，因为 DIVD 指令通过保留站换名已经解除了与 ADDD 的 WAR 相关

    ![1700657937551](images/1700657937551.png)
  - 一直到 15 拍，MULTD 执行完毕

    ![1700657994105](images/1700657994105.png)
  - 16，MULTD 写回，通过 CDB 送入寄存器和 DIVD，DIVD 开始执行

    ![1700658030709](images/1700658030709.png)
  - 直到 56 拍，DIVD 执行完毕

    ![1700658071505](images/1700658071505.png)
  - 57，DIVD 写回，通过 CDB 送寄存器

    ![1700658104663](images/1700658104663.png)

循环实例这里不再过多赘述，只用记住一点：当分支指令没有执行完时，后续指令不允许流出

优缺点：

- 优点
  - 分布式硬件冲突检测。
  - 利用寄存器换名，彻底消除 WAW 和 WAR 这两种名相关
  - 如果多个保留站等待同一个操作数，当操作数在 CDB 上广播时，他们可以同时获得所需的数据
  - 对于存储器访问， 动态存储器地址判别技术可解决 RAW 冲突（取操作数时判断）、WAR 和 WAW 冲突（存操作数时判断）
  - 能够达到很高的性能。
- 缺点
  - 高复杂性：需要大量硬件
  - 存在瓶颈：单个公共数据总线（CDB）引发竞争
    - 额外的 CDB：在每个保留站上需要为每条 CDB 设置重复的硬件接口
  - 为了保证正确的异常行为，对指令的执行有一个限制：一旦有一条分支指令还没有执行完，其后的指令是不允许进入执行段

指令乱序增大了异常处理的复杂度

- 不精确异常（Imprecise Exception）：当指令 i 导致发生异常时，处理机的现场（状态）与严格按程序顺序执行不同。
- 精确异常（Precise Exception）：处理机现场跟严格按程序顺序执行时指令 i 的现场相同。
- 不精确异常产生的原因：
  - 流水线可能已经执行完按程序顺序是位于指令 i 之后的指令
  - 流水线可能还没完成按程序顺序是指令 i 之前的指令

### 4.3 控制相关的动态解决技术

动态预测的理由

- n 流出的处理器加速上限为 n
- Amdahl 定律提示：在较低 CPI 机器上，控制相关导致的空转对机器性能影响大

前述的静态策略：分支延迟槽

分支预测：

- 预测分支是否成功
- 执行目标指令

#### 4.3.1 分支预测缓冲 BPB

分支预测缓冲是一个小的存储器阵列

- 每个单元最小可以只有 1 位，记录最近一次分支是否成功的信息
- 预测位为 1 时，表示预测分支成功，并从目标位置开始取指令
- 在预测错误时，要作废已经预取和分析的指令，恢复现场，并从另一条分支路径重新取指令。

![1700658766761](images/1700658766761.png)

一位 BPB：

- 状态转移图

  ![1700658807072](images/1700658807072.png)
- 当分支不成功时，将会发生连续两侧预测出错

2 位 BPB

- 状态转移图

  ![1700658873480](images/1700658873480.png)
- 容忍出两次错误

实现方案：

- 实现一个小而特殊的 “cache”，利用指令地址进行索引，在 IF 流水段访问
- 为指令 cache 中每一块增加附加位，与指令一起取出

对于改进 MIPS，BPB 不起作用

#### 4.3.2 分支目标缓冲 BTB

BTB 每个单元包括：

- 分支指令地址
- 分支目标地址
- 分支预测标识

结构：

![1700659203351](images/1700659203351.png)

执行过程：

![1700659218243](images/1700659218243.png)

分支预测局限性：

- 准确性 80%-90%
- 性能依赖于
  - 程序类型
  - 缓冲区大小
- 预测失效开销的优化
  - 预取不同分支路径指令：但是会引入其他开销，比如存储系统端口加倍

#### 4.3.3 基于硬件的前瞻执行

基本思想：

- 对分支指令的结果进行猜测，并假设这个猜测总是对的，然后按这个猜测结果继续取、流出和执行后续的指令。
- 执行指令的结果不是写回到寄存器或存储器，而是写入一个称为再定序缓冲器 ROB（ReOrder Buffer）中 。等到相应的指令得到“确认”（commit）（即确实是应该执行的）之后，才将结果写入寄存器或存储器。

结合了三种思想：

- 采用动态预测选择后续执行的指令
- 在控制相关的结果还未出来时，前瞻的执行后续指令
- 对基本块采用动态调度

扩充 tomasulo 算法就可以支持前瞻执行

- 把写结果再分成写结果和指令确认段

  - 写结果段：
    - 把结果写入 ROB 中
    - 通过 CDB 传送数据
  - 确认段：
    - 如果猜测正确：把 ROB 中结果写入寄存器
    - 猜测错误：刷新 ROB 从另一条路径重新执行
- 允许乱序执行，但必须顺序确认
- 部件扩充

  ![1700659822534](images/1700659822534.png)
- ROB 字段

  - 指令类型：分支、store、寄存器操作
  - 状态：支出指令是否完成以及数据已经就绪
  - 目标地址：写入的寄存器号或内存地址
  - 数据值：要写入的值
- 保留站增加目标地址字段：对应 ROB 的编号
- 算法阶段：

  - 流出：**RS 和 ROB 有空闲**就发射指令
  - 执行
  - 写结果
  - 确认

实例：

- 指令

  ![1700660091642](images/1700660091642.png)
- 时延

  - LD：1
  - ADDD/SUBD：2
  - MULTD：9
  - DIVD：40
- 1，第一个 LD 流出，写入 ROB 中

  ![1700660187326](images/1700660187326.png)
- 2，第二个 LD 流出

  ![1700660210635](images/1700660210635.png)
- 3，第一个 LD 写回，注意：这里写入到 ROB 中，并不写入寄存器中，因为还未确认。MULTD 流出

  ![1700660327998](images/1700660327998.png)
- 4，第一个 LD 确认，结果从 ROB 中写入寄存器中。第二个 LD 写回，数据通过 CDB 送入 ROB 和 MULTD 和流出的 SUBD，MULTD 开始执行，SUBD 不执行的原因是这时处于流出段，下一拍才开始执行

  ![1700660415564](images/1700660415564.png)
- 5，第二个 LD 确认数据从 ROB 写回寄存器，DIVD 流出，SUBD 开始执行

  ![1700660471831](images/1700660471831.png)
- 6，ADDD 流出，SUBD 执行完毕

  ![1700660824487](images/1700660824487.png)
- 7，SUBD 写回，通过 CDB 送 ROB 和 ADDD，ADDD 开始执行

  ![1700660866822](images/1700660866822.png)
- 8，SUBD 无法确认，因为前面存在未确认的指令，而确认必须按序，ADDD 执行完毕

  ![1700660934424](images/1700660934424.png)
- 9，ADDD 写回

  ![1700660991257](images/1700660991257.png)
- 直到第 12 拍，MULTD 执行完毕

  ![1700661049800](images/1700661049800.png)
- 13，MULTD 写回，通过 CDB 送 DIVD 和 ROB，DIVD 开始执行

  ![1700661085957](images/1700661085957.png)
- 14，MULTD 确认，ROB 写入寄存器

  ![1700661149812](images/1700661149812.png)
- 15，SUBD 确认
- 直到 52 拍，DIVD 执行完毕
- 53，DIVD 写回
- 54，DIVD 确认
- 55，ADDD 确认

### 4.4 多指令流出技术

- 多指令流出处理器
  - 实现一个时钟周期内流出多条指令时
  - 达到 CPI 小于 1
- 多流出处理器 2 种基本结构
  - 超标量（Superscalar）
    - 超标量每个时钟周期流出的指令数不定
    - 可以编译器静态调度，也可以硬件动态调度
  - 超长指令字（ VLIW， Very long Instruction Word）
    - 每个时钟周期流出的指令数是固定的，只能通过编译静态调度

![1700661340556](images/1700661340556.png)

#### 4.4.1 静态超标量

每个周期发送 1-8 条不存在相关的指令

假设有这样一个超标量机器

- 每个周期可以流出两条指令

  - 一条取、存、分支、整数指令
  - 一条浮点指令
- 理想情况

  ![1700662230778](images/1700662230778.png)
- 存在的技术问题

  - 每个时钟周期流出两条指令意味着同时取两条指令（64 位），译码两条指令（64 位）
  - 假设：指令按要求组合成对，且与 64 位边界对齐，整数指令顺序在前
  - 需要使得浮点部件流水化或增加相关检测部件来减少结构相关
  - 另一个限制超标量流水线性能发挥的障碍是取操作和分支操作的延迟
  - 取操作指令的结果不能在本周期和下一个周期使用
  - 分支指令肯定是指令组合的第一条指令，影响配对指令和后续两条指令，分支延迟也变为 3 条指令
- 实例：一般需要更有效的编译技术、硬件调度技术和更复杂的指令译码技术才能有效利用超标量技术的并行度

  - 代码

    ![1700662323849](images/1700662323849.png)
  - 循环展开 5 次进行调度

    ![1700662433762](images/1700662433762.png)

超标量可以获得更好的性能，但是硬件复杂性大幅增加

#### 4.4.2 动态多指令流出

多指令流出+动态调度

![1700662573330](images/1700662573330.png)

![1700662587750](images/1700662587750.png)

![1700662690989](images/1700662690989.png)

![1700662699017](images/1700662699017.png)

#### 4.4.3 超长指令字

一条指令包含多个操作

例子

- 每个指令字包含

  - 两个访存操作
  - 两个浮点操作
  - 一个整数或分支操作
- 代码

  ![1700662813153](images/1700662813153.png)
- 循环展开五次

  ![1700662851966](images/1700662851966.png)
- 展开 7 次

  ![1700662867059](images/1700662867059.png)

  ![1700662881397](images/1700662881397.png)
- 展开三次无调度

  ![1700662904558](images/1700662904558.png)
- 展开 10 次有调度

  ![1700662925648](images/1700662925648.png)

技术难题

- 从线性代码片段中产生足够的操作需要进行激进的循环展开，这增大了代码大小
- 无论指令是否被充满，没有被使用的功能单元也在指令字编码过程中占据了相应的位。将近一半的指令是被浪费掉的
  - 在主存中压缩指令，在 cache 中解压缩指令
- VLIW 带来了二进制代码兼容性问题
  - 采用机器代码翻译或仿真模拟的方法解决移植的问题

多指令流出的技术难题

- 程序所固有的指令级并行性
- 硬件实现上的困难
- 超标量和超长指令字处理器固有的技术限制
- 设计难点
  - 访存开销
  - 硬件复杂性
  - 编译器技术

## 第五章 存储层次

### 5.1 存储器的层次结构

#### 5.1.1 多级存储层次

存储器的三个主要指标：

- 容量、大
- 速度、快
- 每位价格、低

这三个要求时互相矛盾的

![1700712915536](images/1700712915536.png)

#### 5.1.2 存储层次的性能参数

考虑两级存储层次

![1700713805149](images/1700713805149.png)

- 存储容量$S$
  整个系统的存储容量$S=$$S_2$
- 每位价格$C$
  $C=\frac{C_1S_1+C_2S_2}{S_1+S_2}$
- 命中率$H$和失效率$F$
  - 命中率：CPU 访存时，在$M_1$中找到信息的概率
    $H=\frac{N_1}{N_1+N_2}$
  - 失效率：$F=1-H$
- 平均访存时间$T_A$
  $T_A=HT_1+(1-H)(T_1+T_M)=T_1+(1-H)T_M=T_1+FT_M$
  - 第一次访存时间
    - 命中：$T_1$
    - 不命中：$T_1+T_M$,$T_M=T_2+T_B$
      - $T_M$：失效开销，从向$M_2$发出请求到数据块调入$M_1$中的时间
      - $T_2$：$M_2$的访问时间
      - $T_B$：从$M_2$把一个数据送入$M_1$中的时间

#### 5.1.3 两种存储层次的关系

- 三级存储系统

  - Cahce
  - 主存
  - 辅存
- 两种存储层次

  - Cache-主存
  - 主存-辅存

  ![1700714717241](images/1700714717241.png)

#### 5.1.4 存储层次的 4 个问题

- 映像规则
- 查找算法
- 替换算法
- 写策略

### 5.2 Cache 基本知识

#### 5.2.5 Cache 结构

- 例子

  - 容量：8KB
  - 块大小：32B
  - 块数：256
  - 直接映射
  - 写直达-不按写分配
  - 写缓冲器大小：4 个 块
  - 内存地址：34 位（29 块地址（21tag+8index）、5 块内地址）
- 结构图

  ![1700715308543](images/1700715308543.png)
- 读命中工作过程

  ![1700715339354](images/1700715339354.png)
- 写命中工作过程

  ![1700715420648](images/1700715420648.png)
- 读失效

  ![1700715444016](images/1700715444016.png)
- 写失效

  ![1700715459278](images/1700715459278.png)

分离 cache 和混合 cache：指令和数据是保存在两个 cache 中还是单独各有一个 cache

分离 cache 失效率：各自失效率乘上访问概率再相加

#### 5.2.6 cache 性能分析

- 平均访存时间：命中时间+不命中率\*不命中开销
- CPU 时间
  - （CPU 执行周期数+存储器停顿周期数）\*时钟周期时间
  - $IC\times (CPI_{exe}+\text{每条指令平均存储器停顿周期数})\times \text{时钟周期时间}$
  - 存储器停顿周期数=访存次数\*失效率\*失效开销

#### 5.2.7 改进 cache 性能

- 降低失效率
- 减少失效开销
- 减少命中时间

![1700716591341](images/1700716591341.png)

### 5.3 降低 cache 失效率的办法

三种失效

- 强制性失效：第一次访问
- 容量失效：因为容量不足被替换后重新访问。随着容量增加而减少，**不受相联度影响**
- 冲突失效：被冲突后重新访问。**相联度越高，冲突失效越少**

2:1 的 cache 经验规则：大小为 N 的直接映像 cache 失效率约等于大小为 N/2 的两路组相联 cache 失效率

减少三种失效的方法：

- 强制性失效：增加块大小，预取
- 容量失效：增加容量
- 冲突失效：提高相联度

许多降低失效率的方法都会增加失效开销或命中时间

#### 5.3.1 调节 cache 块大小

失效率与块大小关系

- 对于给定 cache 容量，当块大小增加失效率开始下降，后来反而上升
- cache 容量越大，失效率达到最低的块大小就越大

增加块大小会增加失效开销

#### 5.3.2 提高相联度

相联度超过 8 之后意义不大

2:1 的 cache 经验规则：大小为 N 的直接映像 cache 失效率约等于大小为 N/2 的两路组相联 cache 失效率

提高相联度会增加命中时间

![1700718337993](images/1700718337993.png)

#### 5.3.3 Vivtim cache

基本思想：在 Cache 和它从下一级存储器调数据的通路之间设置一个全相联的小 Cache，用于存放被替换出去的块(称为 Victim)，以备重用。失效时先检查 Vivtim 中是否有要请求的块，如果有直接调入 cache，没有再访问下一级存储器

作用：减小冲突失效

伪相联 cache：采用和 vivtim cache 相近的思想

- 在逻辑上把直接映象 Cache 的空间上下平分为两个区。对于任何一次访问， 伪相联 Cache 先按直接映象 Cache 的方式去处理。若命中（快命中）， 则其访问过程与直接映象 Cache 的情况一样。若不命中， 则再到另一区相应的位置去查找。 若找到，则发生了伪命中（慢命中）， 否则就只好访问下一级存储器。
- 命中时间小，失效率低
- 多种命中时间会使 CPU 流水线设计复杂

#### 5.3.4 硬件预取

在 CPU 提出对指令或数据的请求之前进行预取，放入 Cache 或者外缓冲器中。硬件预取通常由 cache 之外的硬件完成

比如：指令失效时，取被请求的指令块放入 cache 和顺序的下一指令块放入缓冲器中，如果某次被请求的指令快在缓冲器中，则取消对该块的访存请求，直接从缓冲器中读取，同时发出对下一指令块的预取请求。

#### 5.3.5 编译器控制的预取

由编译器加入预取指令，在数据被用到之前发出预取请求

预取类型

- 预取数据存放位置
  - 寄存器预取
  - cache 预取
- 预取的故障处理方式
  - 故障性预取：出现虚地址故障或访问越界，抛出异常
  - 非故障性预取：出现虚地址故障或访问越界，不抛出异常，只是转为不预取

只有在预取数据同时，CPU 还能正常执行才有意义：Cache 在等待数据返回时，仍能接受请求。非阻塞 cache

循环是预取优化的主要对象

- 失效开销小：展开 1~2 次
- 失效开销大：展开许多次

每次预取还会产生一条指令的开销

- 保证这种开销不会超过预取带来的收益
- 编译器可以把重点放在可能会导致不命中的访问上，减少不必要的预取

#### 5.3.6 编译器优化

基本思想：在编译时，对程序中的指令和数据进行重新组织，降低 cache 的失效率（指令失效和数据失效）

- 重新组织程序而不影响正确性：把其中的几个重要过程重新排序，可能减少冲突失效，**降低指令的不命中率**
- 如果编译器知道一个分支指令很可能会成功转移，那么它就可以通过以下两步来改善空间局部性

  - 将转移目标处的基本块和紧跟着该分支指令后的基本块进行对调
  - 把该分支指令换为操作语义相反的分支指令
- 降低数据失效主要是对数组的优化

  - 数组合并

    ![1700719595586](images/1700719595586.png)
  - 内外循环交换

    ![1700719609497](images/1700719609497.png)
  - 循环融合

    ![1700719630058](images/1700719630058.png)

    ![1700719639006](images/1700719639006.png)
  - 分块

#### 5.3.7 总结

![1700719671391](images/1700719671391.png)

### 5.4 减少 cache 失效开销

#### 5.4.1 写缓冲及写合并

在写直达 cache 中，写请求都发送到下一级存储层次中，所以经常使用写缓冲来提高写效率

如何提高写缓冲的效率

- 写合并

  ![1700736359004](images/1700736359004.png)

#### 5.4.2 让读失效优先于写

读不命中时，所读单元最新值可能在写缓冲器中

解决办法

- 推迟读失效的处理：增加读失效的开销
- 让读失效优先于写
  - 读失效时先检查写缓冲器中内容：增加硬件

#### 5.4.3 请求字处理

尽早把请求字发送给 CPU

- 尽早重启动：调块时，从块的起始位置开始读取，一旦请求字到达立即送 CPU
- 请求字优先：调块时，从请求字所在位置读起，第一个读出请求字后立即送 CPU

在以下情况效果不大

- cache 块比较小
- 下一条指令正好访问同一 cache 块的另一部分

#### 5.4.4 多级 cache

![1700736839355](images/1700736839355.png)

![1700736850573](images/1700736850573.png)

当第二级 cache 比第一级大得多时，两级 cache 的全局失效率和第二级 cache 相同的单级 cache 的失效率非常接近

第二级 cache 的参数

- 容量：一般比第一级 cache 大得多
- 相联度：可以采用较高的相联度或伪相联
- 块大小：可以采用较大的块
- 多级包容和多级互斥：第一级的数据是否总是同时存在于二级 cache 中

#### 5.4.5 非阻塞 cache

cache 失效时仍允许 CPU 进行其他的命中访问，允许失效下命中

- 进一步提升：多重失效下命中
- 可同时处理的不命中次数越多，所带来的性能提升越大

#### 5.4.6 总结

![1700737205786](images/1700737205786.png)

### 5.5 减少命中时间

#### 5.5.1 容量小、结构简单的 cache

- 硬件越简单，速度越快
- 应使 cache 足够小，可以和 CPU 放在同一块芯片上
- 一种折中方案：Cache 标识放在片内，数据放在片外

#### 5.5.2 虚拟 cache

物理 cache：地址转换和访问 cache 串行进行，访问速度慢

虚拟 cache：直接使用虚拟地址访问 cache

- 优点：命中时不需要进行地址转换。不命中地址转换和访问 cache 也是并行进行的
- 缺点

  - 不同进程可能使用相同虚地址指向不同的物理地址
    - 进程切换时清空 cache
    - 在地址字段中增加 PID 字段
  - 同一物理地址可能有不同形式的虚拟地址
    - 硬件检查并作废相同物理地址的副本
    - 页着色，通过软件强制别名的某些位相同
- 虚拟索引+物理标识

  ![1700737747092](images/1700737747092.png)

#### 5.5.3 cache 访问流水化

当第一级 cache 的命中时间是多个时钟时，将其访问按流水方式组织

![1700737897280](images/1700737897280.png)

#### 5.5.4 多体 cache

将 cache 组织位多个独立的 banks，支持并行访问

![1700737967720](images/1700737967720.png)

作用

- 当多个体利用同一个组索引进行访存时，它可以使组相联结构的 Cache 中的一组数据和 Tag 同时被访问，加快查找时间
- 当多个体可以利用不同地址进行独立访问时，它可以更有效地支持 CPU 发出的多个访存请求，减小 Cache 的平均命中时间，增大 Cache 的吞吐率

#### 5.5.5 路预测

每一组 cache 保存一些预测位，标识下次访问本组时应命中的块。命中时只用比较一个块的 tag，不命中再比较其他的

一旦预测错误会有更长的命中时间

#### 5.5.6 Trace cache

开发指令级并行的挑战：当要每个时钟周期流出超过 4 条指令时，要提供足够多条彼此互不相关的指令是很困难的

trace cache：

- 保存的是 CPU 实际执行的动态指令序列
- 地址映像机制复杂
- 相同的指令序列有可能被当作条件分支的不同选择而重复存放
- 能提高指令 cache 的空间利用率

#### 5.5.7 总结

![1700738338494](images/1700738338494.png)

### 5.6 主存

性能指标：

- 延迟
- 带宽

![1700738684297](images/1700738684297.png)

#### 5.6.1 存储器组织技术

增加存储器宽度：一次送多个字

![1700738719179](images/1700738719179.png)

![1700738801007](images/1700738801007.png)

采用简单的多体交叉存储器

- 高位交叉和低位交叉

  - 低位交叉编址

    ![1700738957044](images/1700738957044.png)
  - 高位交叉编址

    ![1700738976385](images/1700738976385.png)
- 同时启动和分时启动

  - 同时启动

    ![1700739004209](images/1700739004209.png)
  - 分时启动

    ![1700739016633](images/1700739016633.png)
- 失效开销：地址传送和数据访问都是并行进行的，但是数据的传送是串行的，所以一共有 44 个周期

独立存储体：设置多个存储控制器，使多个体能独立操作，以便同时进行多个独立的访存

#### 5.6.2 存储器芯片技术

DRAM 和 SRAM

![1700739340805](images/1700739340805.png)

DIMM

![1700739385505](images/1700739385505.png)

DRAM 芯片优化技术

- 芯片内部优化技术是提高主存系统性能的一个重要方面
- SDRAM：，DRAM 接口增加一个时钟信号可使 DRAM 能针对一个请求连续同步地传输多个数据而不需同步开销
- DDR：在 DRAM 时钟的上沿和下沿都进行数据传输，可把数据传输率提高一倍
- CDRAM:带 Cache 的 DRAM，DRAM 芯片里集成一个小的 SRAM，暂存最后读出行数据

### 5.7 虚拟存储器

#### 5.7.3 虚存和cache关系的例子

CPU使用虚地址发出请求，TLB通过虚地址中的虚页号查出TLB数据，L1cache使用虚拟cache通过虚地址页内偏移查出tag，比较tag和TLB数据是否相同，相同则将L1cache中读出的数据送入CPU，如果不同，则利用物理地址查找L2cache。

### 5.8 进程保护和虚存实例

![1700739817407](images/1700739817407.png)

## 第六章 输入输出系统
